{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "import librosa\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "FileNames = {\"train\":\"ml-fmi-23-2020//train.txt\", \"valid\":\"ml-fmi-23-2020//validation.txt\", \"test\":\"ml-fmi-23-2020//test.txt\", \"ex\":\"ml-fmi-23-2020//sample_submission.txt\",\"pred\":\"ml-fmi-23-2020//predictions.txt\"}\n",
    "\n",
    "AudioFolders = {\"train\":\".//ml-fmi-23-2020//audio//train//\", \"valid\":\"ml-fmi-23-2020//audio//validation//\", \"test\":\"ml-fmi-23-2020//audio//test//\"}\n",
    "\n",
    "def readCsv (fileName, hasLables):\n",
    "    data = []\n",
    "    with open(fileName, \"r\", newline='\\n') as csvfile:\n",
    "        for row in csv.reader(csvfile, delimiter=','):\n",
    "            data.extend(row)\n",
    "    if hasLables:\n",
    "        data = np.transpose(np.array(data).reshape((len(data)//2, 2))) \n",
    "    else:\n",
    "        data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def writeCsv (data, labels, fileName = FileNames['pred']):\n",
    "    with open(fileName, \"w\", newline='\\n') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['name', 'label'])\n",
    "        for row in np.transpose([data, labels]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "def getData (folderName, dataNames):\n",
    "    data = []\n",
    "    for dataName in dataNames:\n",
    "        audio = librosa.load(AudioFolders[folderName]+dataName)[0]\n",
    "        data.append(librosa.amplitude_to_db(abs(librosa.stft(audio))).reshape(-1))        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_name, train_labels = readCsv(FileNames['train'], hasLables=True)\n",
    "valid_data_name, valid_labels = readCsv(FileNames['valid'], hasLables=True)\n",
    "test_data_name                = readCsv(FileNames['test'],  hasLables=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = getData('train', train_data_name)\n",
    "valid_data = getData('valid', valid_data_name)\n",
    "test_data  = getData('test',  test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate model\n",
    "knn = KNeighborsClassifier(15, metric='l1')\n",
    "knn.fit(train_data, train_labels)\n",
    "valid_pred_knn = knn.predict(valid_data)\n",
    "good_knn = np.argwhere(valid_pred_knn==valid_labels).reshape(-1)\n",
    "print (len(good_knn)/len(valid_pred_knn))\n",
    "confusion_matrix(valid_pred_knn, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict tests\n",
    "knn = KNeighborsClassifier(15, metric='l1')\n",
    "knn.fit(np.concatenate ((train_data, valid_data)), np.concatenate ((train_labels, valid_labels)))\n",
    "pred_knn = knn.predict(test_data)\n",
    "writeCsv(test_data_name, pred_knn)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}