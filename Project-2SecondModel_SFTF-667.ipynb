{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python_speech_features\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "from python_speech_features import mfcc, delta, logfbank\n",
    "from random import randint\n",
    "import librosa\n",
    "\n",
    "\n",
    "FileNames = {\"train\":\"ml-fmi-23-2020//train.txt\", \"valid\":\"ml-fmi-23-2020//validation.txt\", \"test\":\"ml-fmi-23-2020//test.txt\", \"ex\":\"ml-fmi-23-2020//sample_submission.txt\",\"pred\":\"ml-fmi-23-2020//predictions.txt\"}\n",
    "\n",
    "AudioFolders = {\"train\":\"ml-fmi-23-2020//audio//train//\", \"valid\":\"ml-fmi-23-2020//audio//validation//\", \"test\":\"ml-fmi-23-2020//audio//test//\"}\n",
    "\n",
    "sr   = 16000 # Sample Rate   - 16 kHz\n",
    "wlen = 0.025 # window length - 25 ms = 400 samples\n",
    "slen = 0.01  # step   length - 10 ms = 160 samples \n",
    "nfft = 512 \n",
    "\n",
    "def readCsv (fileName, hasLables):\n",
    "    data = []\n",
    "    with open(fileName, \"r\", newline='\\n') as csvfile:\n",
    "        for row in csv.reader(csvfile, delimiter=','):\n",
    "            data.extend(row)\n",
    "    if hasLables:\n",
    "        data = np.transpose(np.array(data).reshape((len(data)//2, 2))) \n",
    "    else:\n",
    "        data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def writeCsv (data, labels, fileName = FileNames['pred']):\n",
    "    with open(fileName, \"w\", newline='\\n') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['name', 'label'])\n",
    "        for row in np.transpose([data, labels]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "def getData (folderName, dataNames):\n",
    "    data = []\n",
    "    for dataName in dataNames:\n",
    "        audio = librosa.load(AudioFolders[folderName]+dataName)[0]\n",
    "        data.append(librosa.amplitude_to_db(abs(librosa.stft(audio))))#.reshape(-1))\n",
    "        # data.append(np.abs(fft(wav.read(AudioFolders[folderName]+dataName)[1])))\n",
    "        # data.append(mfcc(wav.read(AudioFolders[folderName]+dataName)[1], numcep=12))#.reshape(-1))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_name, train_labels = readCsv(FileNames['train'], hasLables=True)\n",
    "valid_data_name, valid_labels = readCsv(FileNames['valid'], hasLables=True)\n",
    "test_data_name                = readCsv(FileNames['test'],  hasLables=False)\n",
    "# writeCsv(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-57.697765 50.504\n0.0 1.0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 1025, 44), (1000, 1025, 44), (3000, 1025, 44))"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# train_data = getData('train', train_data_name)\n",
    "# valid_data = getData('valid', valid_data_name)\n",
    "# test_data  = getData('test',  test_data_name)\n",
    "# mi = min([train_data.min(), valid_data.min(), test_data.min()])\n",
    "# ma = max([train_data.max(), valid_data.max(), test_data.max()])\n",
    "# print (mi, ma)\n",
    "# train = (train_data - mi) / (ma-mi)\n",
    "# valid = (valid_data - mi) / (ma-mi)\n",
    "# test =  (test_data  - mi) / (ma-mi)\n",
    "# mi = min([train.min(), valid.min(), test.min()])\n",
    "# ma = max([train.max(), valid.max(), test.max()])\n",
    "# print (mi, ma)\n",
    "# train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 1025, 44, 1), (1000, 1025, 44, 1), (3000, 1025, 44, 1))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "initialShape = train.shape\n",
    "train = train.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = valid.shape\n",
    "valid = valid.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = test.shape\n",
    "test = test.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_9 (Conv2D)            (None, 1025, 44, 16)      336       \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 1025, 44, 16)      5136      \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 205, 11, 16)       0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 36080)             0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                1154592   \n_________________________________________________________________\ndense_11 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_12 (Dense)             (None, 2)                 34        \n=================================================================\nTotal params: 1,160,626\nTrainable params: 1,160,626\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 406s 51ms/step - loss: 0.5390 - accuracy: 0.7149 - val_loss: 0.5578 - val_accuracy: 0.7070\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x175f99abe08>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = train, \n",
    "    y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "    epochs = 1, # first time 6-7 epochs and after increase by one (around 0.72)\n",
    "    verbose = 1, # progress bar\n",
    "    # validation_split = 0.1,\n",
    "    validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('3thirdmodel6')\n",
    "loaded_model = load_model('3thirdmodel6')\n",
    "pred = np.array(['0' if a > b else '1' for a, b in loaded_model.predict(valid)])\n",
    "sum(pred == valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(['0' if a > b else '1' for a, b in model.predict(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeCsv(test_data_name, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit on both train and valid \n",
    "# train_valid = []\n",
    "# train_valid.extend (train)\n",
    "# train_valid.extend (valid)\n",
    "# train_valid = np.array(train_valid)\n",
    "# train_valid_labels = []\n",
    "# train_valid_labels.extend (train_labels)\n",
    "# train_valid_labels.extend (valid_labels)\n",
    "# train_valid_labels = np.array(train_valid_labels)\n",
    "# model.fit(\n",
    "#     x = train_valid, \n",
    "#     y = np.array([[1,0] if label == '0' else [0,1] for label in train_valid_labels]), \n",
    "#     epochs = 1, \n",
    "#     verbose = 1, # progress bar\n",
    "#     # validation_split = 0.1,\n",
    "#     # validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "#     shuffle = True\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}