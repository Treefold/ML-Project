{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "from python_speech_features import mfcc, delta, logfbank\n",
    "from random import randint\n",
    "import librosa\n",
    "\n",
    "\n",
    "FileNames = {\"train\":\"//kaggle//input//ml-fmi-23-2020//train.txt\", \"valid\":\"//kaggle//input//ml-fmi-23-2020//validation.txt\", \"test\":\"//kaggle//input//ml-fmi-23-2020//test.txt\", \"pred\":\"//kaggle//output//ml-fmi-23-2020//predictions.txt\"}\n",
    "\n",
    "\n",
    "AudioFolders = {\"train\":\"//kaggle//input//ml-fmi-23-2020//train//train//\", \"valid\":\"//kaggle//input//ml-fmi-23-2020//validation//validation//\", \"test\":\"//kaggle//input//ml-fmi-23-2020//test//test//\"}\n",
    "\n",
    "sr   = 16000 # Sample Rate   - 16 kHz\n",
    "wlen = 0.025 # window length - 25 ms = 400 samples\n",
    "slen = 0.01  # step   length - 10 ms = 160 samples \n",
    "nfft = 512 \n",
    "\n",
    "def readCsv (fileName, hasLables):\n",
    "    data = []\n",
    "    with open(fileName, \"r\", newline='\\n') as csvfile:\n",
    "        for row in csv.reader(csvfile, delimiter=','):\n",
    "            data.extend(row)\n",
    "    if hasLables:\n",
    "        data = np.transpose(np.array(data).reshape((len(data)//2, 2))) \n",
    "    else:\n",
    "        data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def writeCsv (data, labels, fileName = FileNames['pred']):\n",
    "    with open(fileName, \"w\", newline='\\n') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['name', 'label'])\n",
    "        for row in np.transpose([data, labels]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "def getData (folderName, dataNames):\n",
    "    data = []\n",
    "    for dataName in dataNames:\n",
    "        audio = librosa.load(AudioFolders[folderName]+dataName)[0]\n",
    "        data.append(librosa.amplitude_to_db(abs(librosa.stft(audio))))#.reshape(-1))\n",
    "#         data.append(np.abs(fft(wav.read(AudioFolders[folderName]+dataName)[1])))\n",
    "#         data.append(mfcc(wav.read(AudioFolders[folderName]+dataName)[1], numcep=12))#.reshape(-1))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_name, train_labels = readCsv(FileNames['train'], hasLables=True)\n",
    "valid_data_name, valid_labels = readCsv(FileNames['valid'], hasLables=True)\n",
    "test_data_name                = readCsv(FileNames['test'],  hasLables=False)\n",
    "# writeCsv(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = getData('train', train_data_name)\n",
    "valid_data = getData('valid', valid_data_name)\n",
    "test_data  = getData('test',  test_data_name)\n",
    "mi = min([train_data.min(), valid_data.min(), test_data.min()])\n",
    "ma = max([train_data.max(), valid_data.max(), test_data.max()])\n",
    "print (mi, ma)\n",
    "train = (train_data - mi) / (ma-mi)\n",
    "valid = (valid_data - mi) / (ma-mi)\n",
    "test =  (test_data  - mi) / (ma-mi)\n",
    "mi = min([train.min(), valid.min(), test.min()])\n",
    "ma = max([train.max(), valid.max(), test.max()])\n",
    "print (mi, ma)\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialShape = train.shape\n",
    "train = train.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = valid.shape\n",
    "valid = valid.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = test.shape\n",
    "test = test.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "noModel = '7-stft'\n",
    "\n",
    "# for kaggle\n",
    "# import os\n",
    "# try:\n",
    "#     os.mkdir('//kaggle//working//Models//')\n",
    "# except: pass\n",
    "# try:\n",
    "#     os.mkdir('//kaggle//working//Models//'+noModel)\n",
    "# except: pass\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (5,2), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (5,2), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy', 'mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoch+1, epoch+6+25):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = epoch+1, \n",
    "        initial_epoch = epoch,\n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    # change where to save when not on kaggle\n",
    "    model.save('//kaggle//working//Models//' + noModel + '//' + ('0' if epoch < 9 else '') + str(epoch+1) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(['0' if a > b else '1' for a, b in model.predict(test)])\n",
    "writeCsv(test_data_name, pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}