{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python_speech_features\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.fftpack import fft\n",
    "from python_speech_features import mfcc, delta, logfbank\n",
    "from random import randint\n",
    "import librosa\n",
    "\n",
    "\n",
    "FileNames = {\"train\":\"ml-fmi-23-2020//train.txt\", \"valid\":\"ml-fmi-23-2020//validation.txt\", \"test\":\"ml-fmi-23-2020//test.txt\", \"ex\":\"ml-fmi-23-2020//sample_submission.txt\",\"pred\":\"ml-fmi-23-2020//predictions.txt\"}\n",
    "\n",
    "AudioFolders = {\"train\":\"ml-fmi-23-2020//audio//train//\", \"valid\":\"ml-fmi-23-2020//audio//validation//\", \"test\":\"ml-fmi-23-2020//audio//test//\"}\n",
    "\n",
    "sr   = 16000 # Sample Rate   - 16 kHz\n",
    "wlen = 0.025 # window length - 25 ms = 400 samples\n",
    "slen = 0.01  # step   length - 10 ms = 160 samples \n",
    "nfft = 512 \n",
    "\n",
    "def readCsv (fileName, hasLables):\n",
    "    data = []\n",
    "    with open(fileName, \"r\", newline='\\n') as csvfile:\n",
    "        for row in csv.reader(csvfile, delimiter=','):\n",
    "            data.extend(row)\n",
    "    if hasLables:\n",
    "        data = np.transpose(np.array(data).reshape((len(data)//2, 2))) \n",
    "    else:\n",
    "        data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def writeCsv (data, labels, fileName = FileNames['pred']):\n",
    "    with open(fileName, \"w\", newline='\\n') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['name', 'label'])\n",
    "        for row in np.transpose([data, labels]):\n",
    "            writer.writerow(row)\n",
    "\n",
    "def getData (folderName, dataNames):\n",
    "    data = []\n",
    "    for dataName in dataNames:\n",
    "        audio = librosa.load(AudioFolders[folderName]+dataName)[0]\n",
    "        data.append(librosa.amplitude_to_db(abs(librosa.stft(audio))))#.reshape(-1))\n",
    "        # data.append(np.abs(fft(wav.read(AudioFolders[folderName]+dataName)[1])))\n",
    "        # data.append(mfcc(wav.read(AudioFolders[folderName]+dataName)[1], numcep=12))#.reshape(-1))\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_name, train_labels = readCsv(FileNames['train'], hasLables=True)\n",
    "valid_data_name, valid_labels = readCsv(FileNames['valid'], hasLables=True)\n",
    "test_data_name                = readCsv(FileNames['test'],  hasLables=False)\n",
    "# writeCsv(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-57.697765 50.504\n0.0 1.0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 1025, 44), (1000, 1025, 44), (3000, 1025, 44))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# train_data = getData('train', train_data_name)\n",
    "# valid_data = getData('valid', valid_data_name)\n",
    "# test_data  = getData('test',  test_data_name)\n",
    "# mi = min([train_data.min(), valid_data.min(), test_data.min()])\n",
    "# ma = max([train_data.max(), valid_data.max(), test_data.max()])\n",
    "# print (mi, ma)\n",
    "# train = (train_data - mi) / (ma-mi)\n",
    "# valid = (valid_data - mi) / (ma-mi)\n",
    "# test =  (test_data  - mi) / (ma-mi)\n",
    "# mi = min([train.min(), valid.min(), test.min()])\n",
    "# ma = max([train.max(), valid.max(), test.max()])\n",
    "# print (mi, ma)\n",
    "# train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 1025, 44, 1), (1000, 1025, 44, 1), (3000, 1025, 44, 1))"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "initialShape = train.shape\n",
    "train = train.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = valid.shape\n",
    "valid = valid.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = test.shape\n",
    "test = test.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-83.08197591063329 74.26606555409005\n0.0 1.0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 99, 12), (1000, 99, 12), (3000, 99, 12))"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# train_data1 = getData('train', train_data_name)\n",
    "# valid_data1 = getData('valid', valid_data_name)\n",
    "# test_data1 = getData('test',  test_data_name)\n",
    "# mi = min([train_data1.min(), valid_data1.min(), test_data1.min()])\n",
    "# ma = max([train_data1.max(), valid_data1.max(), test_data1.max()])\n",
    "# print (mi, ma)\n",
    "# train1 = (train_data1 - mi) / (ma-mi)\n",
    "# valid1 = (valid_data1 - mi) / (ma-mi)\n",
    "# test1 =  (test_data1  - mi) / (ma-mi)\n",
    "# mi = min([train1.min(), valid1.min(), test1.min()])\n",
    "# ma = max([train1.max(), valid1.max(), test1.max()])\n",
    "# print (mi, ma)\n",
    "# train1.shape, valid1.shape, test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialShape = train1.shape\n",
    "train1 = train1.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = valid1.shape\n",
    "valid1 = valid1.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "initialShape = test.shape\n",
    "test1 = test1.reshape(initialShape[0], initialShape[1], initialShape[2], 1)\n",
    "train1.shape, valid1.shape, test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((8000, 1025, 44, 1), (1000, 1025, 44, 1), (3000, 1025, 44, 1))"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "train, train1 = train1, train\n",
    "valid, valid1 = valid1, valid\n",
    "test,  test1  = test1,  test\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_17\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_44 (Conv2D)           (None, 1025, 44, 16)      160       \n_________________________________________________________________\nconv2d_45 (Conv2D)           (None, 1025, 44, 16)      2320      \n_________________________________________________________________\nconv2d_46 (Conv2D)           (None, 1025, 44, 32)      4640      \n_________________________________________________________________\nmax_pooling2d_23 (MaxPooling (None, 341, 14, 32)       0         \n_________________________________________________________________\nflatten_15 (Flatten)         (None, 152768)            0         \n_________________________________________________________________\ndense_41 (Dense)             (None, 32)                4888608   \n_________________________________________________________________\ndense_42 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_43 (Dense)             (None, 2)                 34        \n=================================================================\nTotal params: 4,896,290\nTrainable params: 4,896,290\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# 1\n",
    "noModel = '1-stft'\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu', strides=(1,1), padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(MaxPool2D((3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])#, 'mae', 'mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8000 samples, validate on 1000 samples\nEpoch 2/2\n8000/8000 [==============================] - 458s 57ms/step - loss: 0.6907 - accuracy: 0.5416 - val_loss: 0.6891 - val_accuracy: 0.4900\nTrain on 8000 samples, validate on 1000 samples\nEpoch 3/3\n8000/8000 [==============================] - 455s 57ms/step - loss: 0.6601 - accuracy: 0.6031 - val_loss: 0.5974 - val_accuracy: 0.6680\nTrain on 8000 samples, validate on 1000 samples\nEpoch 4/4\n8000/8000 [==============================] - 462s 58ms/step - loss: 0.6121 - accuracy: 0.6650 - val_loss: 0.6278 - val_accuracy: 0.6290\nTrain on 8000 samples, validate on 1000 samples\nEpoch 5/5\n8000/8000 [==============================] - 458s 57ms/step - loss: 0.5833 - accuracy: 0.6840 - val_loss: 0.5968 - val_accuracy: 0.6670\nTrain on 8000 samples, validate on 1000 samples\nEpoch 6/6\n8000/8000 [==============================] - 472s 59ms/step - loss: 0.5455 - accuracy: 0.7212 - val_loss: 0.5509 - val_accuracy: 0.7170\nTrain on 8000 samples, validate on 1000 samples\nEpoch 7/7\n8000/8000 [==============================] - 456s 57ms/step - loss: 0.4909 - accuracy: 0.7573 - val_loss: 0.5406 - val_accuracy: 0.7310\nTrain on 8000 samples, validate on 1000 samples\nEpoch 8/8\n8000/8000 [==============================] - 481s 60ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5459 - val_accuracy: 0.7280\nTrain on 8000 samples, validate on 1000 samples\nEpoch 9/9\n8000/8000 [==============================] - 463s 58ms/step - loss: 0.3354 - accuracy: 0.8520 - val_loss: 0.5755 - val_accuracy: 0.7300\nTrain on 8000 samples, validate on 1000 samples\nEpoch 10/10\n8000/8000 [==============================] - 454s 57ms/step - loss: 0.2399 - accuracy: 0.9003 - val_loss: 0.7177 - val_accuracy: 0.7340\nTrain on 8000 samples, validate on 1000 samples\nEpoch 11/11\n8000/8000 [==============================] - 462s 58ms/step - loss: 0.1383 - accuracy: 0.9482 - val_loss: 0.9948 - val_accuracy: 0.6930\nTrain on 8000 samples, validate on 1000 samples\nEpoch 12/12\n8000/8000 [==============================] - 459s 57ms/step - loss: 0.0745 - accuracy: 0.9739 - val_loss: 1.1115 - val_accuracy: 0.7290\nTrain on 8000 samples, validate on 1000 samples\nEpoch 13/13\n8000/8000 [==============================] - 457s 57ms/step - loss: 0.0462 - accuracy: 0.9864 - val_loss: 1.3552 - val_accuracy: 0.7080\nTrain on 8000 samples, validate on 1000 samples\nEpoch 14/14\n8000/8000 [==============================] - 455s 57ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 1.4999 - val_accuracy: 0.7250\nTrain on 8000 samples, validate on 1000 samples\nEpoch 15/15\n8000/8000 [==============================] - 451s 56ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 1.7566 - val_accuracy: 0.7130\n"
    }
   ],
   "source": [
    "for epoch in range(1,15):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = epoch+1, \n",
    "        initial_epoch = epoch,\n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    model.save('ml-fmi-23-2020//Models//' + noModel + '//' + str(epoch) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = '4-753' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + noModel + '//' + epoch)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in saved_model.predict(valid)])\n",
    "sum(pred==valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(['0' if a > b else '1' for a, b in saved_model.predict(test)])\n",
    "writeCsv(test_data_name, pred, 'ml-fmi-23-2020//Models//'+ model +'//predictions-' + model + '_' + epoch + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_22 (Conv2D)           (None, 1025, 44, 16)      336       \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 1025, 44, 16)      5136      \n_________________________________________________________________\nmax_pooling2d_14 (MaxPooling (None, 205, 11, 16)       0         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 36080)             0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 32)                1154592   \n_________________________________________________________________\ndense_20 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_21 (Dense)             (None, 2)                 34        \n=================================================================\nTotal params: 1,160,626\nTrainable params: 1,160,626\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# 2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 378s 47ms/step - loss: 0.6939 - accuracy: 0.5061 - val_loss: 0.6925 - val_accuracy: 0.5280\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 372s 46ms/step - loss: 0.6906 - accuracy: 0.5281 - val_loss: 0.6742 - val_accuracy: 0.6420\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.6616 - accuracy: 0.6084 - val_loss: 0.6721 - val_accuracy: 0.5910\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.6282 - accuracy: 0.6485 - val_loss: 0.6183 - val_accuracy: 0.6670\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.5956 - accuracy: 0.6775 - val_loss: 0.5856 - val_accuracy: 0.7140\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.5636 - accuracy: 0.7023 - val_loss: 0.5731 - val_accuracy: 0.6920\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.5379 - accuracy: 0.7199 - val_loss: 0.5659 - val_accuracy: 0.7150\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.5164 - accuracy: 0.7449 - val_loss: 0.5465 - val_accuracy: 0.7210\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.4896 - accuracy: 0.7559 - val_loss: 0.5433 - val_accuracy: 0.7210\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 366s 46ms/step - loss: 0.4556 - accuracy: 0.7785 - val_loss: 0.5738 - val_accuracy: 0.7110\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 362s 45ms/step - loss: 0.4278 - accuracy: 0.8006 - val_loss: 0.5769 - val_accuracy: 0.7350\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.4029 - accuracy: 0.8139 - val_loss: 0.6047 - val_accuracy: 0.7150\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.3730 - accuracy: 0.8280 - val_loss: 0.6242 - val_accuracy: 0.7200\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 362s 45ms/step - loss: 0.3467 - accuracy: 0.8422 - val_loss: 0.6284 - val_accuracy: 0.7150\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 361s 45ms/step - loss: 0.3090 - accuracy: 0.8634 - val_loss: 0.6393 - val_accuracy: 0.7270\n"
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = 1, \n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    model.save('ml-fmi-23-2020//Models//2//' + str(epoch) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_24 (Conv2D)           (None, 1025, 44, 16)      336       \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 1025, 44, 16)      5136      \n_________________________________________________________________\nmax_pooling2d_15 (MaxPooling (None, 205, 11, 16)       0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 205, 11, 32)       10272     \n_________________________________________________________________\nmax_pooling2d_16 (MaxPooling (None, 41, 2, 32)         0         \n_________________________________________________________________\nflatten_8 (Flatten)          (None, 2624)              0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 32)                84000     \n_________________________________________________________________\ndense_23 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_24 (Dense)             (None, 2)                 34        \n=================================================================\nTotal params: 100,306\nTrainable params: 100,306\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# 3\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,4)))\n",
    "model.add(Conv2D(32, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 371s 46ms/step - loss: 0.6928 - accuracy: 0.5135 - val_loss: 0.6899 - val_accuracy: 0.5580\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 368s 46ms/step - loss: 0.6621 - accuracy: 0.5920 - val_loss: 0.6120 - val_accuracy: 0.6650\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 367s 46ms/step - loss: 0.6118 - accuracy: 0.6535 - val_loss: 0.5808 - val_accuracy: 0.6990\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 368s 46ms/step - loss: 0.5970 - accuracy: 0.6686 - val_loss: 0.5834 - val_accuracy: 0.6770\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 10181s 1s/step - loss: 0.5793 - accuracy: 0.6856 - val_loss: 0.5656 - val_accuracy: 0.7050\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 453s 57ms/step - loss: 0.5651 - accuracy: 0.6986 - val_loss: 0.6095 - val_accuracy: 0.6530\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 468s 58ms/step - loss: 0.5420 - accuracy: 0.7179 - val_loss: 0.5655 - val_accuracy: 0.7010\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 445s 56ms/step - loss: 0.5312 - accuracy: 0.7279 - val_loss: 0.5593 - val_accuracy: 0.7200\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 455s 57ms/step - loss: 0.5163 - accuracy: 0.7331 - val_loss: 0.5254 - val_accuracy: 0.7390\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 450s 56ms/step - loss: 0.5110 - accuracy: 0.7406 - val_loss: 0.5700 - val_accuracy: 0.7070\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 446s 56ms/step - loss: 0.4926 - accuracy: 0.7566 - val_loss: 0.5332 - val_accuracy: 0.7310\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 442s 55ms/step - loss: 0.4831 - accuracy: 0.7631 - val_loss: 0.5388 - val_accuracy: 0.7350\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 444s 55ms/step - loss: 0.4643 - accuracy: 0.7717 - val_loss: 0.5274 - val_accuracy: 0.7380\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 464s 58ms/step - loss: 0.4452 - accuracy: 0.7915 - val_loss: 0.5325 - val_accuracy: 0.7340\nTrain on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 439s 55ms/step - loss: 0.4373 - accuracy: 0.7933 - val_loss: 0.5629 - val_accuracy: 0.7200\n"
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = 1, \n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    model.save('ml-fmi-23-2020//Models//3//' + str(epoch) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8000 samples, validate on 1000 samples\nEpoch 1/1\n8000/8000 [==============================] - 434s 54ms/step - loss: 0.4224 - accuracy: 0.7999 - val_loss: 0.5437 - val_accuracy: 0.7350\nTrain on 8000 samples, validate on 1000 samples\nEpoch 2/2\n8000/8000 [==============================] - 445s 56ms/step - loss: 0.4048 - accuracy: 0.8126 - val_loss: 0.5587 - val_accuracy: 0.7330\nTrain on 8000 samples, validate on 1000 samples\nEpoch 3/3\n8000/8000 [==============================] - 405s 51ms/step - loss: 0.3926 - accuracy: 0.8209 - val_loss: 0.5574 - val_accuracy: 0.7380\nTrain on 8000 samples, validate on 1000 samples\nEpoch 4/4\n8000/8000 [==============================] - 409s 51ms/step - loss: 0.3739 - accuracy: 0.8322 - val_loss: 0.5420 - val_accuracy: 0.7490\nTrain on 8000 samples, validate on 1000 samples\nEpoch 5/5\n8000/8000 [==============================] - 403s 50ms/step - loss: 0.3591 - accuracy: 0.8459 - val_loss: 0.5491 - val_accuracy: 0.7530\nTrain on 8000 samples, validate on 1000 samples\nEpoch 6/6\n8000/8000 [==============================] - 416s 52ms/step - loss: 0.3401 - accuracy: 0.8509 - val_loss: 0.6297 - val_accuracy: 0.7310\nTrain on 8000 samples, validate on 1000 samples\nEpoch 7/7\n8000/8000 [==============================] - 403s 50ms/step - loss: 0.3376 - accuracy: 0.8509 - val_loss: 0.6513 - val_accuracy: 0.7240\nTrain on 8000 samples, validate on 1000 samples\nEpoch 8/8\n8000/8000 [==============================] - 405s 51ms/step - loss: 0.3289 - accuracy: 0.8551 - val_loss: 0.6268 - val_accuracy: 0.7330\nTrain on 8000 samples, validate on 1000 samples\nEpoch 9/9\n8000/8000 [==============================] - 396s 50ms/step - loss: 0.3115 - accuracy: 0.8644 - val_loss: 0.6570 - val_accuracy: 0.7360\nTrain on 8000 samples, validate on 1000 samples\nEpoch 10/10\n8000/8000 [==============================] - 397s 50ms/step - loss: 0.3115 - accuracy: 0.8646 - val_loss: 0.6407 - val_accuracy: 0.7200\nTrain on 8000 samples, validate on 1000 samples\nEpoch 11/11\n 352/8000 [>.............................] - ETA: 6:29 - loss: 0.2654 - accuracy: 0.8892"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-214acd735d96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# validation_split = 0.1,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'0'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'1'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = epoch+1, \n",
    "        initial_epoch = epoch,\n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    model.save('ml-fmi-23-2020//Models//4//' + str(epoch) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "778"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = '7-stft-detailed//6'\n",
    "epoch = '11-778' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in saved_model.predict(valid)])\n",
    "sum(pred==valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ml-fmi-23-2020//Models//7-stft-detailed//6//predictions-7-stft-detailed//6_11-778.txt'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0879efc39158>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'1'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwriteCsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ml-fmi-23-2020//Models//'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'//predictions-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-93c84ef2cec4>\u001b[0m in \u001b[0;36mwriteCsv\u001b[1;34m(data, labels, fileName)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwriteCsv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFileNames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml-fmi-23-2020//Models//7-stft-detailed//6//predictions-7-stft-detailed//6_11-778.txt'"
     ]
    }
   ],
   "source": [
    "pred = np.array(['0' if a > b else '1' for a, b in saved_model.predict(test)])\n",
    "writeCsv(test_data_name, pred, 'ml-fmi-23-2020//Models//'+ model +'//predictions-' + model.replace('//', '_') + '_' + epoch + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 8100 samples, validate on 900 samples\nEpoch 1/1\n8100/8100 [==============================] - 17s 2ms/step - loss: 0.5013 - accuracy: 0.7659 - val_loss: 0.5724 - val_accuracy: 0.7189\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x1f09f30a888>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "# # fit on both train and valid \n",
    "# train_valid = []\n",
    "# train_valid.extend (train)\n",
    "# train_valid.extend (valid)\n",
    "# train_valid = np.array(train_valid)\n",
    "# train_valid_labels = []\n",
    "# train_valid_labels.extend (train_labels)\n",
    "# train_valid_labels.extend (valid_labels)\n",
    "# train_valid_labels = np.array(train_valid_labels)\n",
    "# model.fit(\n",
    "#     x = train_valid, \n",
    "#     y = np.array([[1,0] if label == '0' else [0,1] for label in train_valid_labels]), \n",
    "#     epochs = 1, \n",
    "#     verbose = 1, # progress bar\n",
    "#     # validation_split = 0.1,\n",
    "#     # validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "#     shuffle = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.array(['0' if a > b else '1' for a, b in model.predict(test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeCsv(test_data_name, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "383"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sum(pred!=pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noModel = '7-stft_'\n",
    "\n",
    "# for kaggle, comment them for other use\n",
    "import os\n",
    "try:\n",
    "    os.mkdir('//kaggle//working//Models//')\n",
    "except: pass\n",
    "try:\n",
    "    os.mkdir('//kaggle//working//Models//'+noModel)\n",
    "except: pass\n",
    "# end of for kaggle\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same', input_shape = train[0].shape))\n",
    "model.add(Conv2D(16, (5,4), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (5,2), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((5,2)))\n",
    "model.add(Conv2D(32, (5,2), activation='relu', strides=1, padding='same'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoch+1, epoch+6+15):\n",
    "    model.fit(\n",
    "        x = train, \n",
    "        y = np.array([[1,0] if label == '0' else [0,1] for label in train_labels]), \n",
    "        epochs = epoch+1, \n",
    "        initial_epoch = epoch,\n",
    "        verbose = 1, # progress bar\n",
    "        # validation_split = 0.1,\n",
    "        validation_data = (valid, np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])),\n",
    "        shuffle = True\n",
    "    )\n",
    "    pred = np.array(['0' if a > b else '1' for a, b in model.predict(valid)])\n",
    "    # change where to save when not on kaggle\n",
    "    model.save('//kaggle//working//Models//' + noModel + '//' + ('0' if epoch < 10 else '') + str(epoch) + '-' + str(sum(pred==valid_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a682b93d60c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmae\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvalid_labels_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'0'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "valid_labels_val = np.array([[1,0] if label == '0' else [0,1] for label in valid_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 779 \nmae = 0.263045354537916 \nmse = 0.1629291475414958\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//6_14-779'\n",
    "epoch1 = model[-6:] # epoch-validScore\n",
    "saved_model1 = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch1)\n",
    "pred1_val = saved_model1.predict(valid)\n",
    "pred1 = np.array(['0' if a > b else '1' for a, b in pred1_val])\n",
    "print (\"sum =\", sum(pred1==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred1_val), \"\\nmse =\", mse(valid_labels_val, pred1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 773 \nmae = 0.29725884530114755 \nmse = 0.16151130637433542\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//5_13-773'\n",
    "epoch = model[-6:] #'13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 767 \nmae = 0.28568741813817566 \nmse = 0.16552062911885457\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//0_13-767'\n",
    "epoch = '13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 778 \nmae = 0.2971525987325676 \nmse = 0.16204545836793252\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//6_14-779'\n",
    "epoch = '11-778' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 773 \nmae = 0.3013813749161527 \nmse = 0.16530229217481746\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//9_11-773'\n",
    "epoch = model[-6:] #'13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 766 \nmae = 0.2999433258618228 \nmse = 0.17322470717130112\n"
    }
   ],
   "source": [
    "model = '11'\n",
    "epoch4 = '20-766' # epoch-validScore\n",
    "saved_model4 = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch4)\n",
    "pred4_val = saved_model4.predict(valid)\n",
    "pred4 = np.array(['0' if a > b else '1' for a, b in pred4_val])\n",
    "print (\"sum =\", sum(pred4==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred4_val), \"\\nmse =\", mse(valid_labels_val, pred4_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 764 \nmae = 0.30865380359962 \nmse = 0.16954820583976155\n"
    }
   ],
   "source": [
    "model = '3-stft_2'\n",
    "epoch2 = '13-764' # epoch-validScore\n",
    "saved_model2 = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch2)\n",
    "pred2_val = saved_model2.predict(valid)\n",
    "pred2 = np.array(['0' if a > b else '1' for a, b in pred2_val])\n",
    "print (\"sum =\", sum(pred2==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred2_val), \"\\nmse =\", mse(valid_labels_val, pred2_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 749 \nmae = 0.30719971271880786 \nmse = 0.1740840166978262\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//1_08-749'\n",
    "epoch = model[-6:] #'13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 753 \nmae = 0.3016043451037472 \nmse = 0.17647691567253554\n"
    }
   ],
   "source": [
    "model = '4'\n",
    "epoch3 = '4-753' # epoch-validScore\n",
    "saved_model3 = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch3)\n",
    "pred3_val = saved_model3.predict(valid)\n",
    "pred3 = np.array(['0' if a > b else '1' for a, b in pred3_val])\n",
    "print (\"sum =\", sum(pred3==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred3_val), \"\\nmse =\", mse(valid_labels_val, pred3_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 765 \nmae = 0.3056128543322447 \nmse = 0.1741405791593657\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//2_20-765'\n",
    "epoch = model[-6:] #'13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sum = 774 \nmae = 0.2534599614840391 \nmse = 0.18167244150867268\n"
    }
   ],
   "source": [
    "model = '7-stft-detailed//4_24-774'\n",
    "epoch = model[-6:] #'13-767' # epoch-validScore\n",
    "saved_model = load_model('ml-fmi-23-2020//Models//' + model + '//' + epoch)\n",
    "pred_val = saved_model.predict(valid)\n",
    "pred = np.array(['0' if a > b else '1' for a, b in pred_val])\n",
    "print (\"sum =\", sum(pred==valid_labels), \"\\nmae =\", mae(valid_labels_val, pred_val), \"\\nmse =\", mse(valid_labels_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(['0' if a > b else '1' for a, b in saved_model.predict(test)])\n",
    "writeCsv(test_data_name, pred, 'ml-fmi-23-2020//Models//'+ model +'//predictions-' + model.replace('//', '_') +'txt') # + '_' + epoch + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3000,)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}